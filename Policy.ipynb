{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b831a290663060d6bbcd08c7adbf35f3f8975b354fb04e6990e28cd1cdf56c03"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /home/aditya/miniconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\nInstructions for updating:\nnon-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import pybullet\n",
    "from hier_env import HierarchicalHumanoidEnv\n",
    "from low_level_env import LowLevelHumanoidEnv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer\n",
    "from ray.tune.registry import register_env\n",
    "from ray.tune import function\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env_low(env_config):\n",
    "    import pybullet_envs\n",
    "\n",
    "    return LowLevelHumanoidEnv()\n",
    "\n",
    "\n",
    "def make_env_hier(env_config):\n",
    "    import pybullet_envs\n",
    "\n",
    "    return HierarchicalHumanoidEnv()\n",
    "\n",
    "\n",
    "def policy_mapping_fn(agent_id):\n",
    "    if agent_id.startswith(\"low_level_\"):\n",
    "        return \"low_level_policy\"\n",
    "    else:\n",
    "        return \"high_level_policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DeprecationWarning: wrapping <function policy_mapping_fn at 0x7ff653a60d30> with tune.function() is no longer needed\n"
     ]
    }
   ],
   "source": [
    "ENV_LOW = \"HumanoidBulletEnv-v0-Low\"\n",
    "register_env(ENV_LOW, make_env_low)\n",
    "config_low = {\n",
    "    \"env\": ENV_LOW,\n",
    "    \"num_workers\": 0,\n",
    "    \"num_envs_per_worker\": 1,\n",
    "    \"log_level\": \"WARN\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"monitor\": True,\n",
    "    \"evaluation_num_episodes\": 50,\n",
    "    \"gamma\": 0.995,\n",
    "    \"lambda\": 0.95,\n",
    "    \"clip_param\": 0.2,\n",
    "    \"kl_coeff\": 1.0,\n",
    "    \"num_sgd_iter\": 20,\n",
    "    \"lr\": 0.0005,\n",
    "    \"sgd_minibatch_size\": 8000,\n",
    "    \"train_batch_size\": 24000,\n",
    "    \"model\": {\n",
    "        \"fcnet_hiddens\": [1024, 512],\n",
    "        \"fcnet_activation\": \"tanh\",\n",
    "        \"free_log_std\": True,\n",
    "    },\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "    \"observation_filter\": \"NoFilter\",\n",
    "    \"framework\": \"tf\",\n",
    "}\n",
    "\n",
    "single_env = HierarchicalHumanoidEnv()\n",
    "\n",
    "ENV_HIER = \"HumanoidBulletEnvHier-v0\"\n",
    "register_env(ENV_HIER, make_env_hier)\n",
    "highLevelPolicy = (\n",
    "    None,\n",
    "    single_env.high_level_obs_space,\n",
    "    single_env.high_level_act_space,\n",
    "    {\n",
    "        \"model\": {\n",
    "            \"fcnet_hiddens\": [512, 256],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"free_log_std\": False,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "lowLevelPolicy = (\n",
    "    None,\n",
    "    single_env.low_level_obs_space,\n",
    "    single_env.low_level_act_space,\n",
    "    {\n",
    "        \"model\": {\n",
    "            \"fcnet_hiddens\": [1024, 512],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"free_log_std\": True,\n",
    "        },\n",
    "    },\n",
    ")\n",
    "\n",
    "config = {\n",
    "    \"env\": ENV_HIER,\n",
    "    \"num_workers\": 0,\n",
    "    \"num_envs_per_worker\": 1,\n",
    "    \"multiagent\": {\n",
    "        \"policies\": {\n",
    "            \"high_level_policy\": highLevelPolicy,\n",
    "            \"low_level_policy\": lowLevelPolicy,\n",
    "        },\n",
    "        \"policy_mapping_fn\": function(policy_mapping_fn),\n",
    "    },\n",
    "    \"log_level\": \"WARN\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"monitor\": True,\n",
    "    \"evaluation_num_episodes\": 50,\n",
    "    \"gamma\": 0.995,\n",
    "    \"lambda\": 0.95,\n",
    "    \"clip_param\": 0.2,\n",
    "    \"kl_coeff\": 1.0,\n",
    "    \"num_sgd_iter\": 20,\n",
    "    \"lr\": 0.0005,\n",
    "    \"sgd_minibatch_size\": 12000,\n",
    "    \"train_batch_size\": 36000,\n",
    "    \"batch_mode\": \"complete_episodes\",\n",
    "    \"observation_filter\": \"NoFilter\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-19 19:54:18,652\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.108',\n",
       " 'raylet_ip_address': '192.168.0.108',\n",
       " 'redis_address': '192.168.0.108:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2021-04-19_19-54-18_241771_96224/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2021-04-19_19-54-18_241771_96224/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2021-04-19_19-54-18_241771_96224',\n",
       " 'metrics_export_port': 42237,\n",
       " 'node_id': '0cdbc2626075633c8861828439993514de03833c3f2ff0474e6295c4'}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-19 19:54:42,992\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'default_policy/log_std:0' shape=(17,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "2021-04-19 19:54:44,617\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n",
      "2021-04-19 19:54:44,679\tINFO trainable.py:371 -- Restored on 192.168.0.108 from checkpoint: /home/aditya/ray_results/HWalk_Low_Mimic/PPO_HumanoidBulletEnvLow-v0_699c9_00000_0_2021-04-18_22-14-39/checkpoint_1930/checkpoint-1930\n",
      "2021-04-19 19:54:44,680\tINFO trainable.py:379 -- Current state after restoring: {'_iteration': 1930, '_timesteps_total': None, '_time_total': 42152.27765059471, '_episodes_total': 1118553}\n"
     ]
    }
   ],
   "source": [
    "agentLow = PPOTrainer(config_low)\n",
    "experiment_name = \"HWalk_Low_Mimic\"\n",
    "experiment_id = \"PPO_HumanoidBulletEnvLow-v0_699c9_00000_0_2021-04-18_22-14-39\"\n",
    "checkpoint_num = \"1930\"\n",
    "agentLow.restore(\n",
    "    \"/home/aditya/ray_results/{}/{}/checkpoint_{}/checkpoint-{}\".format(\n",
    "        experiment_name, experiment_id, checkpoint_num, checkpoint_num\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = agentLow.get_policy(\"default_policy\").get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['default_policy/log_std', 'default_policy/fc_1/kernel', 'default_policy/fc_1/bias', 'default_policy/fc_2/kernel', 'default_policy/fc_2/bias', 'default_policy/fc_value_1/kernel', 'default_policy/fc_value_1/bias', 'default_policy/fc_out/kernel', 'default_policy/fc_out/bias', 'default_policy/fc_value_2/kernel', 'default_policy/fc_value_2/bias', 'default_policy/value_out/kernel', 'default_policy/value_out/bias', '_optimizer_variables'])"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "s1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-04-19 20:03:26,365\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "2021-04-19 20:03:26,833\tWARNING deprecation.py:33 -- DeprecationWarning: `framestack` has been deprecated. Use `num_framestacks (int)` instead. This will raise an error in the future!\n",
      "WARNING:tensorflow:\n",
      "The following Variables were used a Lambda layer's call (lambda), but\n",
      "are not present in its tracked objects:\n",
      "  <tf.Variable 'low_level_policy/log_std:0' shape=(17,) dtype=float32>\n",
      "It is possible that this is intended behavior, but it is more likely\n",
      "an omission. This is a strong indication that this layer should be\n",
      "formulated as a subclassed Layer rather than a Lambda layer.\n",
      "2021-04-19 20:03:29,657\tWARNING util.py:47 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "agentHigh = PPOTrainer(config)\n",
    "experiment_name2 = \"HWalk_Hier_Mimic\"\n",
    "experiment_id2 = \"PPO_HumanoidBulletEnvHier-v0_3b65d_00000_0_2021-04-19_15-24-09\"\n",
    "checkpoint_num2 = \"840\"\n",
    "# agentHigh.restore(\n",
    "#     \"/home/aditya/ray_results/{}/{}/checkpoint_{}/checkpoint-{}\".format(\n",
    "#         experiment_name2, experiment_id2, checkpoint_num2, checkpoint_num2\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = agentHigh.get_policy(\"low_level_policy\").get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['low_level_policy/log_std', 'low_level_policy/fc_1/kernel', 'low_level_policy/fc_1/bias', 'low_level_policy/fc_2/kernel', 'low_level_policy/fc_2/bias', 'low_level_policy/fc_value_1/kernel', 'low_level_policy/fc_value_1/bias', 'low_level_policy/fc_out/kernel', 'low_level_policy/fc_out/bias', 'low_level_policy/fc_value_2/kernel', 'low_level_policy/fc_value_2/bias', 'low_level_policy/value_out/kernel', 'low_level_policy/value_out/bias', '_optimizer_variables'])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "s2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['default_policy/log_std', 'default_policy/fc_1/kernel', 'default_policy/fc_1/bias', 'default_policy/fc_2/kernel', 'default_policy/fc_2/bias', 'default_policy/fc_value_1/kernel', 'default_policy/fc_value_1/bias', 'default_policy/fc_out/kernel', 'default_policy/fc_out/bias', 'default_policy/fc_value_2/kernel', 'default_policy/fc_value_2/bias', 'default_policy/value_out/kernel', 'default_policy/value_out/bias', '_optimizer_variables'])"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "s1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.3385599 , -1.1344466 , -1.1837405 , -1.1487037 , -1.4503701 ,\n",
       "       -1.5460362 , -1.4583296 , -1.1097896 , -1.42051   , -1.5193747 ,\n",
       "       -1.5059805 , -0.7800477 , -0.97913575, -1.5724465 , -0.7847039 ,\n",
       "       -1.0035341 , -1.5840968 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "s2['low_level_policy/log_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.3385599 , -1.1344466 , -1.1837405 , -1.1487037 , -1.4503701 ,\n",
       "       -1.5460362 , -1.4583296 , -1.1097896 , -1.42051   , -1.5193747 ,\n",
       "       -1.5059805 , -0.7800477 , -0.97913575, -1.5724465 , -0.7847039 ,\n",
       "       -1.0035341 , -1.5840968 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "s1['default_policy/log_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = agentLow.get_policy().get_weights()\n",
    "w2 = agentHigh.get_policy(\"low_level_policy\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.3385599 , -1.1344466 , -1.1837405 , -1.1487037 , -1.4503701 ,\n",
       "       -1.5460362 , -1.4583296 , -1.1097896 , -1.42051   , -1.5193747 ,\n",
       "       -1.5059805 , -0.7800477 , -0.97913575, -1.5724465 , -0.7847039 ,\n",
       "       -1.0035341 , -1.5840968 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "w1['default_policy/log_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.3385599 , -1.1344466 , -1.1837405 , -1.1487037 , -1.4503701 ,\n",
       "       -1.5460362 , -1.4583296 , -1.1097896 , -1.42051   , -1.5193747 ,\n",
       "       -1.5059805 , -0.7800477 , -0.97913575, -1.5724465 , -0.7847039 ,\n",
       "       -1.0035341 , -1.5840968 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "w2['low_level_policy/log_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "agentHigh.get_policy(\"low_level_policy\").set_weights({\n",
    "    'low_level_policy/log_std': w1['default_policy/log_std']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.3385599 , -1.1344466 , -1.1837405 , -1.1487037 , -1.4503701 ,\n",
       "       -1.5460362 , -1.4583296 , -1.1097896 , -1.42051   , -1.5193747 ,\n",
       "       -1.5059805 , -0.7800477 , -0.97913575, -1.5724465 , -0.7847039 ,\n",
       "       -1.0035341 , -1.5840968 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "agentHigh.get_policy(\"low_level_policy\").get_weights()['low_level_policy/log_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-1.3385599 , -1.1344466 , -1.1837405 , -1.1487037 , -1.4503701 ,\n",
       "       -1.5460362 , -1.4583296 , -1.1097896 , -1.42051   , -1.5193747 ,\n",
       "       -1.5059805 , -0.7800477 , -0.97913575, -1.5724465 , -0.7847039 ,\n",
       "       -1.0035341 , -1.5840968 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "agentHigh.get_policy(\"low_level_policy\").get_state()['low_level_policy/log_std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'low_level_policy/log_std': 'default_policy/log_std',\n",
       " 'low_level_policy/fc_1/kernel': 'default_policy/fc_1/kernel',\n",
       " 'low_level_policy/fc_1/bias': 'default_policy/fc_1/bias',\n",
       " 'low_level_policy/fc_2/kernel': 'default_policy/fc_2/kernel',\n",
       " 'low_level_policy/fc_2/bias': 'default_policy/fc_2/bias',\n",
       " 'low_level_policy/fc_value_1/kernel': 'default_policy/fc_value_1/kernel',\n",
       " 'low_level_policy/fc_value_1/bias': 'default_policy/fc_value_1/bias',\n",
       " 'low_level_policy/fc_out/kernel': 'default_policy/fc_out/kernel',\n",
       " 'low_level_policy/fc_out/bias': 'default_policy/fc_out/bias',\n",
       " 'low_level_policy/fc_value_2/kernel': 'default_policy/fc_value_2/kernel',\n",
       " 'low_level_policy/fc_value_2/bias': 'default_policy/fc_value_2/bias',\n",
       " 'low_level_policy/value_out/kernel': 'default_policy/value_out/kernel',\n",
       " 'low_level_policy/value_out/bias': 'default_policy/value_out/bias',\n",
       " '_optimizer_variables': '_optimizer_variables'}"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "{ k1: k2 for k1, k2 in zip(s.keys(), s1.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "default_policy/log_std low_level_policy/log_std\ndefault_policy/fc_1/kernel low_level_policy/fc_1/kernel\ndefault_policy/fc_1/bias low_level_policy/fc_1/bias\ndefault_policy/fc_2/kernel low_level_policy/fc_2/kernel\ndefault_policy/fc_2/bias low_level_policy/fc_2/bias\ndefault_policy/fc_value_1/kernel low_level_policy/fc_value_1/kernel\ndefault_policy/fc_value_1/bias low_level_policy/fc_value_1/bias\ndefault_policy/fc_out/kernel low_level_policy/fc_out/kernel\ndefault_policy/fc_out/bias low_level_policy/fc_out/bias\ndefault_policy/fc_value_2/kernel low_level_policy/fc_value_2/kernel\ndefault_policy/fc_value_2/bias low_level_policy/fc_value_2/bias\ndefault_policy/value_out/kernel low_level_policy/value_out/kernel\ndefault_policy/value_out/bias low_level_policy/value_out/bias\n_optimizer_variables _optimizer_variables\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(s1.keys(), s2.keys()):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['default_policy/beta1_power', 'default_policy/beta2_power', 'default_policy/default_policy/log_std/Adam', 'default_policy/default_policy/log_std/Adam_1', 'default_policy/default_policy/fc_1/kernel/Adam', 'default_policy/default_policy/fc_1/kernel/Adam_1', 'default_policy/default_policy/fc_1/bias/Adam', 'default_policy/default_policy/fc_1/bias/Adam_1', 'default_policy/default_policy/fc_2/kernel/Adam', 'default_policy/default_policy/fc_2/kernel/Adam_1', 'default_policy/default_policy/fc_2/bias/Adam', 'default_policy/default_policy/fc_2/bias/Adam_1', 'default_policy/default_policy/fc_value_1/kernel/Adam', 'default_policy/default_policy/fc_value_1/kernel/Adam_1', 'default_policy/default_policy/fc_value_1/bias/Adam', 'default_policy/default_policy/fc_value_1/bias/Adam_1', 'default_policy/default_policy/fc_out/kernel/Adam', 'default_policy/default_policy/fc_out/kernel/Adam_1', 'default_policy/default_policy/fc_out/bias/Adam', 'default_policy/default_policy/fc_out/bias/Adam_1', 'default_policy/default_policy/fc_value_2/kernel/Adam', 'default_policy/default_policy/fc_value_2/kernel/Adam_1', 'default_policy/default_policy/fc_value_2/bias/Adam', 'default_policy/default_policy/fc_value_2/bias/Adam_1', 'default_policy/default_policy/value_out/kernel/Adam', 'default_policy/default_policy/value_out/kernel/Adam_1', 'default_policy/default_policy/value_out/bias/Adam', 'default_policy/default_policy/value_out/bias/Adam_1'])"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "s1['_optimizer_variables'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['low_level_policy/beta1_power', 'low_level_policy/beta2_power', 'low_level_policy/low_level_policy/log_std/Adam', 'low_level_policy/low_level_policy/log_std/Adam_1', 'low_level_policy/low_level_policy/fc_1/kernel/Adam', 'low_level_policy/low_level_policy/fc_1/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_1/bias/Adam', 'low_level_policy/low_level_policy/fc_1/bias/Adam_1', 'low_level_policy/low_level_policy/fc_2/kernel/Adam', 'low_level_policy/low_level_policy/fc_2/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_2/bias/Adam', 'low_level_policy/low_level_policy/fc_2/bias/Adam_1', 'low_level_policy/low_level_policy/fc_value_1/kernel/Adam', 'low_level_policy/low_level_policy/fc_value_1/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_value_1/bias/Adam', 'low_level_policy/low_level_policy/fc_value_1/bias/Adam_1', 'low_level_policy/low_level_policy/fc_out/kernel/Adam', 'low_level_policy/low_level_policy/fc_out/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_out/bias/Adam', 'low_level_policy/low_level_policy/fc_out/bias/Adam_1', 'low_level_policy/low_level_policy/fc_value_2/kernel/Adam', 'low_level_policy/low_level_policy/fc_value_2/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_value_2/bias/Adam', 'low_level_policy/low_level_policy/fc_value_2/bias/Adam_1', 'low_level_policy/low_level_policy/value_out/kernel/Adam', 'low_level_policy/low_level_policy/value_out/kernel/Adam_1', 'low_level_policy/low_level_policy/value_out/bias/Adam', 'low_level_policy/low_level_policy/value_out/bias/Adam_1'])"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "s2['_optimizer_variables'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "default_policy/beta1_power                                    low_level_policy/beta1_power\ndefault_policy/beta2_power                                    low_level_policy/beta2_power\ndefault_policy/default_policy/log_std/Adam                    low_level_policy/low_level_policy/log_std/Adam\ndefault_policy/default_policy/log_std/Adam_1                  low_level_policy/low_level_policy/log_std/Adam_1\ndefault_policy/default_policy/fc_1/kernel/Adam                low_level_policy/low_level_policy/fc_1/kernel/Adam\ndefault_policy/default_policy/fc_1/kernel/Adam_1              low_level_policy/low_level_policy/fc_1/kernel/Adam_1\ndefault_policy/default_policy/fc_1/bias/Adam                  low_level_policy/low_level_policy/fc_1/bias/Adam\ndefault_policy/default_policy/fc_1/bias/Adam_1                low_level_policy/low_level_policy/fc_1/bias/Adam_1\ndefault_policy/default_policy/fc_2/kernel/Adam                low_level_policy/low_level_policy/fc_2/kernel/Adam\ndefault_policy/default_policy/fc_2/kernel/Adam_1              low_level_policy/low_level_policy/fc_2/kernel/Adam_1\ndefault_policy/default_policy/fc_2/bias/Adam                  low_level_policy/low_level_policy/fc_2/bias/Adam\ndefault_policy/default_policy/fc_2/bias/Adam_1                low_level_policy/low_level_policy/fc_2/bias/Adam_1\ndefault_policy/default_policy/fc_value_1/kernel/Adam          low_level_policy/low_level_policy/fc_value_1/kernel/Adam\ndefault_policy/default_policy/fc_value_1/kernel/Adam_1        low_level_policy/low_level_policy/fc_value_1/kernel/Adam_1\ndefault_policy/default_policy/fc_value_1/bias/Adam            low_level_policy/low_level_policy/fc_value_1/bias/Adam\ndefault_policy/default_policy/fc_value_1/bias/Adam_1          low_level_policy/low_level_policy/fc_value_1/bias/Adam_1\ndefault_policy/default_policy/fc_out/kernel/Adam              low_level_policy/low_level_policy/fc_out/kernel/Adam\ndefault_policy/default_policy/fc_out/kernel/Adam_1            low_level_policy/low_level_policy/fc_out/kernel/Adam_1\ndefault_policy/default_policy/fc_out/bias/Adam                low_level_policy/low_level_policy/fc_out/bias/Adam\ndefault_policy/default_policy/fc_out/bias/Adam_1              low_level_policy/low_level_policy/fc_out/bias/Adam_1\ndefault_policy/default_policy/fc_value_2/kernel/Adam          low_level_policy/low_level_policy/fc_value_2/kernel/Adam\ndefault_policy/default_policy/fc_value_2/kernel/Adam_1        low_level_policy/low_level_policy/fc_value_2/kernel/Adam_1\ndefault_policy/default_policy/fc_value_2/bias/Adam            low_level_policy/low_level_policy/fc_value_2/bias/Adam\ndefault_policy/default_policy/fc_value_2/bias/Adam_1          low_level_policy/low_level_policy/fc_value_2/bias/Adam_1\ndefault_policy/default_policy/value_out/kernel/Adam           low_level_policy/low_level_policy/value_out/kernel/Adam\ndefault_policy/default_policy/value_out/kernel/Adam_1         low_level_policy/low_level_policy/value_out/kernel/Adam_1\ndefault_policy/default_policy/value_out/bias/Adam             low_level_policy/low_level_policy/value_out/bias/Adam\ndefault_policy/default_policy/value_out/bias/Adam_1           low_level_policy/low_level_policy/value_out/bias/Adam_1\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(s1['_optimizer_variables'].keys(), s2['_optimizer_variables'].keys()):\n",
    "    print(a, ' '*(60 - len(a)), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'low_level_policy/low_level_policy/log_std/Adam'"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "\"default_policy/default_policy/log_std/Adam\".replace(\"default_policy\", \"low_level_policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "No variables in the input matched those in the network. Possible cause: Two networks were defined in the same TensorFlow graph. To fix this, place each network definition in its own tf.Graph.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-9e0a7fbc3d7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m agentHigh.get_policy(\"low_level_policy\").set_state({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'_optimizer_variables'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_optimizer_variables'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m })\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0moptimizer_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_optimizer_variables\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0;31m# Then the Policy's (NN) weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/experimental/tf_utils.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, new_weights)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             ]\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0massign_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;34m\"No variables in the input matched those in the network. \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;34m\"Possible cause: Two networks were defined in the same \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: No variables in the input matched those in the network. Possible cause: Two networks were defined in the same TensorFlow graph. To fix this, place each network definition in its own tf.Graph."
     ]
    }
   ],
   "source": [
    "agentHigh.get_policy(\"low_level_policy\").set_state({\n",
    "    '_optimizer_variables': s1['_optimizer_variables']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "s11 = OrderedDict([(k.replace(\"default_policy\", \"low_level_policy\"), v) for k, v in s1['_optimizer_variables'].items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "low_level_policy/beta1_power <class 'numpy.float32'>\nlow_level_policy/beta2_power <class 'numpy.float32'>\nlow_level_policy/low_level_policy/log_std/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/log_std/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_1/kernel/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_1/kernel/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_1/bias/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_1/bias/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_2/kernel/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_2/kernel/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_2/bias/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_2/bias/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_1/kernel/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_1/kernel/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_1/bias/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_1/bias/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_out/kernel/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_out/kernel/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_out/bias/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_out/bias/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_2/kernel/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_2/kernel/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_2/bias/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/fc_value_2/bias/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/value_out/kernel/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/value_out/kernel/Adam_1 <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/value_out/bias/Adam <class 'numpy.ndarray'>\nlow_level_policy/low_level_policy/value_out/bias/Adam_1 <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for a in s11:\n",
    "    print(a, type(s11[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "True\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\n"
     ]
    }
   ],
   "source": [
    "for a, b in zip(s11.keys(), s2['_optimizer_variables'].keys()):\n",
    "    print(a == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "No variables in the input matched those in the network. Possible cause: Two networks were defined in the same TensorFlow graph. To fix this, place each network definition in its own tf.Graph.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-cecfc7a7989a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m agentHigh.get_policy(\"low_level_policy\").set_state({\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'_optimizer_variables'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ms11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m })\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;31m# Then the Policy's (NN) weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/policy.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSerialized\u001b[0m \u001b[0mlocal\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \"\"\"\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mDeveloperAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/rllib/policy/tf_policy.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mDeveloperAPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverride\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/ray/experimental/tf_utils.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, new_weights)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massignment_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             ]\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0massign_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0;34m\"No variables in the input matched those in the network. \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0;34m\"Possible cause: Two networks were defined in the same \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: No variables in the input matched those in the network. Possible cause: Two networks were defined in the same TensorFlow graph. To fix this, place each network definition in its own tf.Graph."
     ]
    }
   ],
   "source": [
    "agentHigh.get_policy(\"low_level_policy\").set_state({\n",
    "    '_optimizer_variables': s11\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "odict_keys(['low_level_policy/beta1_power', 'low_level_policy/beta2_power', 'low_level_policy/low_level_policy/log_std/Adam', 'low_level_policy/low_level_policy/log_std/Adam_1', 'low_level_policy/low_level_policy/fc_1/kernel/Adam', 'low_level_policy/low_level_policy/fc_1/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_1/bias/Adam', 'low_level_policy/low_level_policy/fc_1/bias/Adam_1', 'low_level_policy/low_level_policy/fc_2/kernel/Adam', 'low_level_policy/low_level_policy/fc_2/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_2/bias/Adam', 'low_level_policy/low_level_policy/fc_2/bias/Adam_1', 'low_level_policy/low_level_policy/fc_value_1/kernel/Adam', 'low_level_policy/low_level_policy/fc_value_1/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_value_1/bias/Adam', 'low_level_policy/low_level_policy/fc_value_1/bias/Adam_1', 'low_level_policy/low_level_policy/fc_out/kernel/Adam', 'low_level_policy/low_level_policy/fc_out/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_out/bias/Adam', 'low_level_policy/low_level_policy/fc_out/bias/Adam_1', 'low_level_policy/low_level_policy/fc_value_2/kernel/Adam', 'low_level_policy/low_level_policy/fc_value_2/kernel/Adam_1', 'low_level_policy/low_level_policy/fc_value_2/bias/Adam', 'low_level_policy/low_level_policy/fc_value_2/bias/Adam_1', 'low_level_policy/low_level_policy/value_out/kernel/Adam', 'low_level_policy/low_level_policy/value_out/kernel/Adam_1', 'low_level_policy/low_level_policy/value_out/bias/Adam', 'low_level_policy/low_level_policy/value_out/bias/Adam_1'])"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "s11.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}